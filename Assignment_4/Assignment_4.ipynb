{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cgvvWbigDxeN",
    "outputId": "5e662a23-27ce-4ad8-e1c2-92d220aec7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(rewards, round):\n",
    "    plt.plot(range(0,round + 1), rewards)\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Mean Reward\")\n",
    "    plt.title(\"Mean Reward per Episode\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "Tz99vn4VMqOd",
    "outputId": "8fbd44ef-54ae-43e4-efb9-d85d8d332126"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round -1 :Initial mean reward -42.30633200638368 --- Initial top 20 reward is 56.54612297857976\n",
      "Start training...\n",
      "Press any key to continue. Please record the final episode jkjk\n",
      "\n",
      "Start testing\n",
      "Final mean reward -15177.622575747579\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def nn_train(gpu = False, size_hidden_layer = 100, learningrate=1e-4, momentum = 0.5, mean_reward_threshold = 100, EPISODEN = 100,  STEPS_PER_EPISODE = 500):\n",
    "\n",
    "    env = gym.make('LunarLander-v2')\n",
    "    env.seed(random_seed)\n",
    "\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self, D_in, H, D_out):\n",
    "            super(Net, self).__init__()\n",
    "            self.linear1 = nn.Linear(D_in, H)\n",
    "            self.relu1 = torch.nn.ReLU()\n",
    "            self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "        def forward(self, x):\n",
    "            \"\"\"\n",
    "            In the forward function we accept a Tensor of input data and we must return\n",
    "            a Tensor of output data. We can use Modules defined in the constructor as\n",
    "            well as arbitrary operators on Tensors.\n",
    "            \"\"\"\n",
    "            l1 = self.linear1(x) \n",
    "            h_relu = self.relu1(l1)\n",
    "            #y_pred = nn.Softmax(self.linear2(h_relu))\n",
    "            y_pred = self.linear2(h_relu)\n",
    "            # y_pred = self.soft_max(self.linear2(h_relu))\n",
    "            return y_pred\n",
    "\n",
    "    def train(episodes_data):\n",
    "        model.train()\n",
    "\n",
    "        for episode in episodes_data:\n",
    "            for data, target in episode:\n",
    "                data = torch.tensor(data, device = device)\n",
    "                target = torch.tensor(target, device = device)\n",
    "                optimizer.zero_grad()\n",
    "                y_pred = model(data)\n",
    "                y_pred = torch.unsqueeze(y_pred, 0)\n",
    "                target = torch.unsqueeze(target, 0)\n",
    "                #y_pred = torch.Tensor(y_pred, device=\"cpu\")\n",
    "                #y_pred = int(np.argmax(y_pred.cpu().detach().numpy()))\n",
    "                # print(y_pred.shape)\n",
    "                loss = criterion(y_pred, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # print(f\"Loss for most recent episode is {loss.item()}\")\n",
    "\n",
    "    #diese methode kann zum erstellen von trainingdaten als auch f√ºr das \n",
    "    #testen des aktuellen modells verwendet werden\n",
    "    def generate_train_data(episoden, rendering):\n",
    "        model.eval()\n",
    "        all_scores = []\n",
    "        episodes = [] # [ [(state, action), (),...()], [(state, action), (),...()], ...]\n",
    "        rewards = []\n",
    "        sm = nn.Softmax(dim=0)\n",
    "        for i in range(episoden):\n",
    "            obs = env.reset() # reset for each new trial  \n",
    "            state_action_pairs_per_episode = [] #[(state, action),(), ...]\n",
    "            episode_reward = 0\n",
    "\n",
    "            for t in range(STEPS_PER_EPISODE): # run for maximum 500 timesteps or until done, whichever is first\n",
    "                #get states and put into network\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    data = torch.tensor(obs, device = device)\n",
    "                    outputs = model(data)\n",
    "#                     print(outputs)\n",
    "                    propability_dist = sm(outputs).cpu().detach().numpy()\n",
    "#                     print(propability_dist)\n",
    "                    outputs = outputs.cpu().detach().numpy()\n",
    "                    choice = np.random.choice(outputs, size=1, p=propability_dist)\n",
    "\n",
    "                    new_action = np.where((outputs == choice))[0][0] # new approach\n",
    "#                 new_action = int(np.argmax(outputs.cpu())) #old approach\n",
    "                state_action_tupel = (obs, new_action)\n",
    "                state_action_pairs_per_episode.append(state_action_tupel)\n",
    "        \n",
    "                if rendering:\n",
    "                    env.render()\n",
    "                obs, reward, done, info = env.step(new_action)\n",
    "                episode_reward+=reward\n",
    "\n",
    "                if done and (not rendering):\n",
    "                  #print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "                    break\n",
    "\n",
    "                #print(episode_reward/STEPS_PER_EPISODE)\n",
    "                episodes.append(state_action_pairs_per_episode)\n",
    "                rewards.append(episode_reward)\n",
    "            env.close()\n",
    "\n",
    "\n",
    "        rewards = np.array(rewards)\n",
    "        episodes = np.array(episodes)\n",
    "        sort_index = rewards.argsort()\n",
    "        top_rewards = rewards[sort_index[::-1]][:20]\n",
    "        top_episodes = episodes[sort_index[::-1]][:20]\n",
    "        return top_episodes, top_rewards.mean(), rewards.mean()\n",
    "\n",
    "    D_in = 8\n",
    "    H = size_hidden_layer\n",
    "    D_out = 4\n",
    "    all_rewards = 0\n",
    "    round = 0 \n",
    "    rewards = []\n",
    "    \n",
    "    model = Net(D_in, H, D_out)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learningrate, momentum=momentum)\n",
    "    if gpu: \n",
    "        model.cuda()\n",
    "\n",
    "    \"\"\" Get initial training episodes  \"\"\"\n",
    "    train_data, top_rewards, all_rewards = generate_train_data(EPISODEN, rendering = False)\n",
    "    print(\"Round -1 :Initial mean reward {} --- Initial top 20 reward is {}\".format(all_rewards, top_rewards, round))\n",
    "    print(\"Start training...\")\n",
    "    rewards.append(all_rewards)\n",
    "\n",
    "    \"\"\" Traing until mean reward hits threshold  \"\"\"\n",
    "    while (all_rewards < mean_reward_threshold):\n",
    "        train(train_data)\n",
    "        train_data, top_rewards, all_rewards = generate_train_data(EPISODEN, rendering = False)\n",
    "        print(\"Round {}: Current mean reward {} --- Top 20 reward is {}\".format(round, all_rewards, top_rewards))\n",
    "        rewards.append(all_rewards)\n",
    "        round = round + 1\n",
    "    \n",
    "    \"\"\" test with one final rendered epsiode  \"\"\"\n",
    "    waiting_mechanism = input(\"Press any key to continue. Please record the final episode \")\n",
    "    print(\"\\nStart testing\")\n",
    "\n",
    "    train_data, top_rewards, all_rewards = generate_train_data(1, rendering = True)\n",
    "    print(\"Final mean reward {}\".format(all_rewards, top_rewards, round))\n",
    "    \n",
    "    plot_rewards(rewards, round)\n",
    "        \n",
    "nn_train(gpu = True, \n",
    "         size_hidden_layer = 500, \n",
    "         learningrate=0.1, \n",
    "         momentum = 0.3, \n",
    "         mean_reward_threshold = -45, \n",
    "         EPISODEN = 100,  \n",
    "         STEPS_PER_EPISODE = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    obs, reward, done, info = env.step(env.action_space.sample()) # take a random action\n",
    "#     if done:\n",
    "#         break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ReinforcementLearning_lunarlanding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
